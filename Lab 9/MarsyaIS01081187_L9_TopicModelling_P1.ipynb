{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Marsya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Marsya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Marsya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk. tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For topic modeling\n",
    "from gensim import corpora \n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Download NLTK Resources\n",
    "nltk. download ('stopwords')\n",
    "nltk. download('punkt')\n",
    "nltk. download('wordnet')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Rafael Nadal Joins Roger Federer in Missing U.S. Open\",\n",
    "    \"Rafael Nadal Is Out of the Australian Open\",\n",
    "    \"Biden Announces Virus Measures\",\n",
    "    \"Biden's Virus Plans Meet Reality\",\n",
    "    \"Where Biden's Virus Plan Stands\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rafael', 'nadal', 'join', 'roger', 'federer', 'missing', 'open'],\n",
       " ['rafael', 'nadal', 'australian', 'open'],\n",
       " ['biden', 'announces', 'virus', 'measure'],\n",
       " ['biden', 'virus', 'plan', 'meet', 'reality'],\n",
       " ['biden', 'virus', 'plan', 'stand']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a set of Eng stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# initialize a Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# tokenize the test into words, convert to lowercase, filter non-alphanumeric, \n",
    "# remove stopwords and lemmatize\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "#preprocess each doc into a list\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a doc-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Gensim dictionary object from the preprocesses docs\n",
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus: bag-of-words representation of the documents \n",
    "#num_topics: number of topics to be extracted by the model \n",
    "#idword-dictionary: dictionary mapping from word IDs to words \n",
    "#passes: number of passes through the corpus during training\n",
    "# Train an LDA model on the corpus with 4 topics using Gensim's LdaModel class\n",
    "lda_model = LdaModel (corpus, num_topics=2, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Interpret Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty List to store dominant topic Labels for each document\n",
    "article_labels = []\n",
    "\n",
    "# iterate over each processed document\n",
    "for i, doc in enumerate(preprocessed_documents):\n",
    "# for each document, convert to box representation\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    # get list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    # determine topic with highest probability\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    # appenf to the list\n",
    "    article_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic\n",
      "                                             Article  Topic\n",
      "0  Rafael Nadal Joins Roger Federer in Missing U....      1\n",
      "1         Rafael Nadal Is Out of the Australian Open      1\n",
      "2                     Biden Announces Virus Measures      0\n",
      "3                   Biden's Virus Plans Meet Reality      0\n",
      "4                    Where Biden's Virus Plan Stands      0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame({\"Article\": documents, \"Topic\": article_labels})\n",
    "\n",
    "# print the datafram\n",
    "print(\"Table with Articles and Topic\")\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic: 0:\n",
      "- \"virus\" (weight: 0.166)\n",
      "- \"biden\" (weight: 0.166)\n",
      "- \"plan\" (weight: 0.119)\n",
      "- \"meet\" (weight: 0.071)\n",
      "- \"reality\" (weight: 0.071)\n",
      "- \"announces\" (weight: 0.071)\n",
      "- \"measure\" (weight: 0.071)\n",
      "- \"stand\" (weight: 0.071)\n",
      "- \"australian\" (weight: 0.024)\n",
      "- \"nadal\" (weight: 0.024)\n",
      "\n",
      "Topic: 1:\n",
      "- \"rafael\" (weight: 0.131)\n",
      "- \"open\" (weight: 0.131)\n",
      "- \"nadal\" (weight: 0.131)\n",
      "- \"federer\" (weight: 0.079)\n",
      "- \"missing\" (weight: 0.079)\n",
      "- \"roger\" (weight: 0.079)\n",
      "- \"join\" (weight: 0.079)\n",
      "- \"australian\" (weight: 0.079)\n",
      "- \"biden\" (weight: 0.027)\n",
      "- \"virus\" (weight: 0.027)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic: {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
